from __future__ import annotations

from dataclasses import dataclass, field
import os
from pathlib import Path
from typing import TypeAlias, Union

import pandas as pd

from mesil.data.clean import set_cleaner
from mesil.data.read import get_delimiter, set_reader

SUPPORTED_EXTENSIONS = ['.csv', '.txt', '.xls', '.xlsx']
SUPPORTED_ANALYSES = [
    'asap',
    'fls-em',
    'fls-exc',
    'ftir',
    'solid-uv',
    'tga',
    'xrd',
    'xrf',
]

PathLike: TypeAlias = Union[os.PathLike, str]

@dataclass
class DataFile:
    r"""A data file.

    Contains data generated by a material characterization, in the scope of Materials Chemistry.

    Attributes:
        path: File's path.
        analysis: Analysis's acronym.
        delimiter: Data separator in csv files.
        raw_data: Raw data, as is in file.
        clean_data: Clean data.
        processed_data: Clean and transformed data.

    Examples:
        >>> DataFile(path='data/raw/tga/2023-05-08/DIC14.txt', analysis='tga')
        DataFile(path=WindowsPath('data/raw/tga/2023-05-08/DIC14.txt'), analysis='tga', delimiter='\t')

        >>> DataFile(path='data/raw/asap/2023-04-19/DIC14.XLS', analysis='ASAP')
        DataFile(path=WindowsPath('data/raw/asap/2023-04-19/DIC14.XLS'), analysis='asap', delimiter='')
    """
    path: PathLike
    analysis: str
    delimiter: str = field(init=False)
    raw_data: pd.DataFrame = field(init=False, repr=False)
    clean_data: pd.DataFrame = field(init=False, repr=False)
    processed_data: pd.DataFrame = field(init=False, repr=False)
    

    def validate_path(self, path, **_) -> Path:
        """Ensures that input path is casted as Pathlib's Path object,
        check if it exists, and if the extension is supported.

        Args:
            path (Path): Input path

        Raises:
            FileNotFoundError: File does not exist.
            ValueError: Extension is currently not supported.

        Returns:
            Path: Validated path.
        """
        path = Path(path)
        if not path.exists():
            raise FileNotFoundError(f'No such file {path}')
        if path.is_dir():
            raise ValueError(
                f'Attribute path should be a file, found dir {path}'
            )
        if not path.suffix.lower() in SUPPORTED_EXTENSIONS:
            raise ValueError(
                f'Extension {path.suffix} not supported, try one of {SUPPORTED_EXTENSIONS}'
            )
        return path

    def validate_analysis(self, analysis, **_) -> str:
        """Ensures analysis is stored in lowercase and that is supported.

        Args:
            analysis (str): Characterization method acronym.

        Raises:
            ValueError: Analysis currently not supported.

        Returns:
            str: Validated analysis
        """
        analysis = analysis.lower()
        if not analysis in SUPPORTED_ANALYSES:
            raise ValueError(
                f'{analysis.upper()} analysis not supported, try one of {SUPPORTED_ANALYSES}'
            )
        return analysis

    def __post_init__(self) -> None:
        """Run validation methods if declared.
        The validation method can be a simple check
        that raises ValueError or a transformation to
        the field value.
        The validation is performed by calling a function named:
            `validate_<field_name>(self, value, field) -> field.type`
        """
        for name, field in self.__dataclass_fields__.items():
            if method := getattr(self, f'validate_{name}', None):
                setattr(self, name, method(getattr(self, name), field=field))

        self.delimiter = (
            get_delimiter(self.path)
            if self.path.suffix.lower() in ['.csv', '.txt']
            else ''
        )

    def read(self) -> DataFile:
        """Read data in formats csv, xls or xlsx from `path` and store it in `raw_data`.

        Returns:
            DataFile: `DataFile` with raw data, as is in file.
        """
        reader = set_reader(self.path.suffix)
        skip_rows = (
            31 if self.analysis == 'tga' else None
        )    # especially needed to read tga data
        self.raw_data = reader(self.path, skip_rows=skip_rows)
        return self

    def clean(self) -> DataFile:
        """Clean a copy of the data contained in `raw_data` and store it in `clean_data`

        Returns:
            DataFile: `DataFile` with clean data. 
        """
        cleaner = set_cleaner(self.analysis)
        self.clean_data = cleaner(self.raw_data)
        return self
        ...

    def transform(self) -> DataFile:
        ...

    def export(self):
        ...
